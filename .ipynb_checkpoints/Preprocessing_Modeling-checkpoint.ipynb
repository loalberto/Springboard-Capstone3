{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import multiprocessing \n",
    "import random\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import gc\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(s):\n",
    "    # retrieves all the filenames in a list of strings\n",
    "    path = './transformed_images/{}'.format(s)\n",
    "    vals = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if os.path.getsize(path + '/'+ filename) == 0 or filename == '.DS_Store':\n",
    "                continue\n",
    "            vals.append(filename)\n",
    "    return sorted(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonp(func, list_of_images, size=(300, 300)):\n",
    "    # for img in list_of_images:\n",
    "    path = func(list_of_images)\n",
    "    # Transforming all the images to size 400x400\n",
    "    current_img = image.load_img(path, target_size=size, color_mode='grayscale')\n",
    "    # makes a matrix\n",
    "    img_ts = image.img_to_array(current_img)\n",
    "    # converts to a vector\n",
    "    img_ts = [img_ts.ravel()]\n",
    "    current_img.close()\n",
    "    try:\n",
    "        # Brings all the new vectors into one giant array\n",
    "        full_mat = np.concatenate((full_mat, img_ts))\n",
    "    except UnboundLocalError:\n",
    "        full_mat = img_ts\n",
    "    return full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonp_wrapper(args):\n",
    "    return tonp(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_filepath(img_name):\n",
    "    # Returns the filepath of a given string\n",
    "    return './transformed_images/Cat/{}'.format(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dog_train_filepath(img_name):\n",
    "    # Returns the filepath of a given string\n",
    "    return './transformed_images/DogTrain/{}'.format(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dog_test_filepath(img_name):\n",
    "    # Returns the filepath of a given string\n",
    "    return './transformed_images/DogTest/{}'.format(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_np(np_array):\n",
    "    # The functiton takes in an np_array to display the image\n",
    "    # This will display the image in grayscale\n",
    "    plt.imshow(np_array, vmin=0, vmax=255, cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_data(cat_filenames, dogtrain_filenames, dogtest_filenames, sample_amount=5000):\n",
    "    cat_data = []\n",
    "    dogtrain_data = []\n",
    "    dogtest_data = []\n",
    "    # for i in range(len(cat_filenames)):\n",
    "    for i in range(sample_amount):\n",
    "        cat_data.append(tonp(get_cat_filepath, cat_filenames[i]))\n",
    "    # for i in range(len(dogtrain_filenames)):\n",
    "    for i in range(sample_amount):\n",
    "        dogtrain_data.append(tonp(get_dog_train_filepath, dogtrain_filenames[i]))\n",
    "    # for i in range(len(dogtest_filenames)):\n",
    "    for i in range(sample_amount):\n",
    "        dogtest_data.append(tonp(get_dog_test_filepath, dogtest_filenames[i]))\n",
    "    dog_data = np.concatenate((dogtest_data, dogtrain_data))\n",
    "    del dogtest_data\n",
    "    del dogtrain_data\n",
    "    gc.collect()\n",
    "    sample_cat = random.sample(cat_data, sample_amount)\n",
    "    cat_label = np.array([1 for _ in range(len(cat_data))])\n",
    "    dog_label = np.array([0 for _ in range(len(dog_data))])\n",
    "    all_data_label = np.concatenate((cat_label[:sample_amount], dog_label))\n",
    "    all_data = np.concatenate((sample_cat, dog_data))\n",
    "    del sample_cat\n",
    "    del dog_data\n",
    "    gc.collect()\n",
    "    split_limit = int(np.floor(0.7 * len(all_data)))\n",
    "    random_index = random.sample(range((len(all_data))), split_limit)\n",
    "    test_idx = set(np.arange(0, sample_amount)) - set(random_index)\n",
    "    X_train = [all_data[i] for i in random_index]\n",
    "    y_train = np.asarray([all_data_label[i] for i in random_index])\n",
    "    X_test = [all_data[i] for i in test_idx]\n",
    "    y_test = np.asarray([all_data_label[i] for i in test_idx])\n",
    "    del cat_data\n",
    "    gc.collect()\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_filenames = get_file_names('Cat')\n",
    "dogtrain_filenames = get_file_names('DogTrain')\n",
    "dogtest_filenames = get_file_names('DogTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = set_up_data(cat_filenames, dogtrain_filenames, dogtest_filenames,\n",
    "                                              sample_amount=100)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).reshape(np.array(X_train).shape[0], 300, 300, 1)\n",
    "X_test = np.asarray(X_test).reshape(np.array(X_test).shape[0], 300, 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 300, 300, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 300, 300, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 300, 300, 1) (21, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3, 300, 300, 1), (3, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4919 - accuracy: 0.3810 - val_loss: 4820.8423 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1459.9001 - accuracy: 0.6667 - val_loss: 4030.0984 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1606.7401 - accuracy: 0.6667 - val_loss: 3224.8269 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff80c136d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# hidden layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), padding='valid',\n",
    "                 activation='relu', input_shape=(300,300,1)))\n",
    "# output layer\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input_shape = (height, width, 1 if it's grayscale)\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(300,300,1), padding='same'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.51% accuracy for the first model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

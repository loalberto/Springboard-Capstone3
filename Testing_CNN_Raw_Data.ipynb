{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(s):\n",
    "    # retrieves all the filenames in a list of strings\n",
    "    path = './image_data/PetImages/{}'.format(s)\n",
    "    vals = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if os.path.getsize(path + '/'+ filename) == 0:\n",
    "                continue\n",
    "            vals.append(filename)\n",
    "    return sorted(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_filepath(img_name):\n",
    "    # Returns the filepath of a given string\n",
    "    return './image_data/PetImages/cat/{}'.format(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dog_train_filepath(img_name):\n",
    "    # Returns the filepath of a given string\n",
    "    return './image_data/PetImages/dogs_train/{}'.format(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dog_test_filepath(img_name):\n",
    "    # Returns the filepath of a given string\n",
    "    return './image_data/PetImages/dogs_test/{}'.format(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing to check is to see how the images' pixels average values look\n",
    "def tonp(list_of_images, size=(200, 200)):\n",
    "    # for img in list_of_images:\n",
    "    path = get_cat_filepath(list_of_images)\n",
    "    # Transforming all the images to size 400x400\n",
    "    current_img = image.load_img(path, target_size=size, color_mode='grayscale')\n",
    "    # makes a matrix\n",
    "    img_ts = image.img_to_array(current_img)\n",
    "    # converts to a vector\n",
    "    img_ts = img_ts.ravel()\n",
    "    current_img.close()\n",
    "    try:\n",
    "        # Brings all the new vectors into one giant array\n",
    "        full_mat = np.concatenate((full_mat, img_ts))\n",
    "    except UnboundLocalError:\n",
    "        full_mat = img_ts\n",
    "    return full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing to check is to see how the images' pixels average values look\n",
    "def tonp_dog_train(list_of_images, size=(200, 200)):\n",
    "    # for img in list_of_images:\n",
    "    path = get_dog_train_filepath(list_of_images)\n",
    "    # Transforming all the images to size 400x400\n",
    "    current_img = image.load_img(path, target_size=size, color_mode='grayscale')\n",
    "    # makes a matrix\n",
    "    img_ts = image.img_to_array(current_img)\n",
    "    # converts to a vector\n",
    "    img_ts = img_ts.ravel()\n",
    "    current_img.close()\n",
    "    try:\n",
    "        # Brings all the new vectors into one giant array\n",
    "        full_mat = np.concatenate((full_mat, img_ts))\n",
    "    except UnboundLocalError:\n",
    "        full_mat = img_ts\n",
    "    return full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing to check is to see how the images' pixels average values look\n",
    "def tonp_dog_test(list_of_images, size=(200, 200)):\n",
    "    # for img in list_of_images:\n",
    "    path = get_dog_test_filepath(list_of_images)\n",
    "    # Transforming all the images to size 400x400\n",
    "    current_img = image.load_img(path, target_size=size, color_mode='grayscale')\n",
    "    # makes a matrix\n",
    "    img_ts = image.img_to_array(current_img)\n",
    "    # converts to a vector\n",
    "    img_ts = img_ts.ravel()\n",
    "    current_img.close()\n",
    "    try:\n",
    "        # Brings all the new vectors into one giant array\n",
    "        full_mat = np.concatenate((full_mat, img_ts))\n",
    "    except UnboundLocalError:\n",
    "        full_mat = img_ts\n",
    "    return full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_np(np_array):\n",
    "    # The functiton takes in an np_array to display the image\n",
    "    # This will display the image in grayscale\n",
    "    plt.imshow(np_array, vmin=0, vmax=255, cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    cat_filenames = get_file_names('cat')\n",
    "    cat_filenames = cat_filenames[1:len(cat_filenames)]\n",
    "    cat_filenames = cat_filenames[:len(cat_filenames) - 1]\n",
    "    dog_filenames = get_file_names('dogs_train')\n",
    "    dog_test_filenames = get_file_names('dogs_test')\n",
    "    # Testing CNN prediction on raw data\n",
    "    pool = multiprocessing.Pool()\n",
    "    # Will get the data in a matrix for the cata data\n",
    "    raw_data = pool.map(tonp, cat_filenames)\n",
    "    # Needs to do this for each of the train and test data of the dog images\n",
    "    dog_train_data = pool.map(tonp_dog_train, dog_filenames)\n",
    "    dog_test_data = pool.map(tonp_dog_test, dog_test_filenames)\n",
    "    # Returns the array in array([[]])\n",
    "    dog_train_data = np.asarray(dog_train_data).reshape(len(dog_train_data), 200, 200, 1)\n",
    "    dog_test_data = np.asarray(dog_test_data).reshape(len(dog_test_data), 200, 200, 1)\n",
    "    raw_data = np.asarray(raw_data)\n",
    "    # Splits the data by 70% for the cat data\n",
    "    lower_split = int(np.ceil(len(raw_data) * .7))\n",
    "    X_train = raw_data[:lower_split].reshape(lower_split, 200, 200, 1)\n",
    "    X_test = raw_data[lower_split:].reshape(len(raw_data) - lower_split, 200, 200 ,1)\n",
    "    # Creates the corresponding labels for each image\n",
    "    dog_y_train = np.array([0 for _ in range(len(dog_train_data))])\n",
    "    y_train = np.array([1 for _ in range(len(X_train))])\n",
    "    # Does the same for the testing data\n",
    "    dog_y_test = np.array([0 for _ in range(len(dog_test_data))])\n",
    "    y_test = np.array([1 for _ in range(len(X_test))])\n",
    "    # Joins everything together and has everything split into training and testing data\n",
    "    X_train = np.concatenate((X_train, dog_train_data))\n",
    "    X_test = np.concatenate((X_test, dog_test_data))\n",
    "    y_train = np.concatenate((y_train, dog_y_train))\n",
    "    y_test = np.concatenate((y_test, dog_y_test))\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    return X_train, y_train, X_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_filenames = get_file_names('cat')\n",
    "cat_filenames = cat_filenames[1:len(cat_filenames)]\n",
    "cat_filenames = cat_filenames[:len(cat_filenames) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dog_filenames = get_file_names('dogs_train')\n",
    "dog_test_filenames = get_file_names('dogs_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing CNN prediction on raw data\n",
    "pool = multiprocessing.Pool()\n",
    "raw_data = pool.map(tonp, cat_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dog_train_data = pool.map(tonp_dog_train, dog_filenames)\n",
    "dog_test_data = pool.map(tonp_dog_test, dog_test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_train_data = np.asarray(dog_train_data).reshape(len(dog_train_data), 200, 200, 1)\n",
    "dog_test_data = np.asarray(dog_test_data).reshape(len(dog_test_data), 200, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166., 168., 172., ...,   0.,   0.,   0.],\n",
       "       [101.,  98., 100., ...,  37.,  46.,  47.],\n",
       "       [255., 255., 255., ..., 255., 254., 231.],\n",
       "       ...,\n",
       "       [ 99.,  94.,  97., ..., 253., 254., 254.],\n",
       "       [ 59.,  55.,  55., ..., 216., 214., 214.],\n",
       "       [154.,  39.,  39., ...,  82.,  84.,  82.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = np.asarray(raw_data)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_split = int(np.ceil(len(raw_data) * .7))\n",
    "X_train = raw_data[:lower_split].reshape(lower_split, 200, 200, 1)\n",
    "X_test = raw_data[lower_split:].reshape(len(raw_data) - lower_split, 200, 200 ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dog_y_train = np.array([0 for _ in range(len(dog_train_data))])\n",
    "y_train = np.array([1 for _ in range(len(X_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2] = 0\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_y_test = np.array([0 for _ in range(len(dog_test_data))])\n",
    "y_test = np.array([1 for _ in range(len(X_test))])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, dog_train_data))\n",
    "X_test = np.concatenate((X_test, dog_test_data))\n",
    "y_train = np.concatenate((y_train, dog_y_train))\n",
    "y_test = np.concatenate((y_test, dog_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12751, 200, 200, 1) (12751,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4750, 200, 200, 1), (4750,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "399/399 [==============================] - 1170s 3s/step - loss: 0.0000e+00 - accuracy: 0.6810 - val_loss: 0.0000e+00 - val_accuracy: 0.7895\n",
      "Epoch 2/3\n",
      "399/399 [==============================] - 3523s 9s/step - loss: 0.0000e+00 - accuracy: 0.6789 - val_loss: 0.0000e+00 - val_accuracy: 0.7895\n",
      "Epoch 3/3\n",
      "399/399 [==============================] - 1140s 3s/step - loss: 0.0000e+00 - accuracy: 0.6884 - val_loss: 0.0000e+00 - val_accuracy: 0.7895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa186491050>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_shape = (height, width, 1 if it's grayscale)\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(200, 200, 1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
